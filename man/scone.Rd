% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/scone_main.R
\name{scone}
\alias{scone}
\title{scone main wrapper: function to apply and evaluate all the normalization schemes}
\usage{
scone(expr, imputation, scaling, k_ruv = 5, k_qc = 5, ruv_negcon = NULL,
  qc = NULL, adjust_bio = c("no", "yes", "force"), adjust_batch = c("no",
  "yes", "force"), bio = NULL, batch = NULL, run = TRUE,
  evaluate = TRUE, eval_pcs = 3, eval_knn = 10, eval_weights = NULL,
  eval_kclust = 2:10, eval_negcon = NULL, eval_poscon = NULL,
  params = NULL, verbose = FALSE, conditional_pam = FALSE)
}
\arguments{
\item{expr}{matrix. The data matrix (genes in rows, cells in columns).}

\item{imputation}{list or function. (A list of) function(s) to be used for imputation.}

\item{scaling}{list or function. (A list of) function(s) to be used for scaling normalization.}

\item{k_ruv}{numeric. The maximum number of factors of unwanted variation (the function will adjust for 1 to k_ruv factors of unwanted variation).
If 0, RUV will not be performed.}

\item{k_qc}{numeric. The maximum number of quality metrics PCs (the function will adjust for 1 to k_qc PCs).
If 0, QC adjustment will not be performed.}

\item{ruv_negcon}{character. The genes to be used as negative controls for RUV. Ignored if k_ruv=0.}

\item{qc}{matrix. The QC metrics to be used for QC adjustment. Ignored if k_qc=0.}

\item{adjust_bio}{character. If 'no' it will not be included in the model; if 'yes', both models with and without 'bio' will be run;
if 'force', only models with 'bio' will be run.}

\item{adjust_batch}{character. If 'no' it will not be included in the model; if 'yes', both models with and without 'batch' will be run;
if 'force', only models with 'batch' will be run.}

\item{bio}{factor. The biological condition to be included in the adjustment model (variation to be preserved).
Ignored, if adjust_bio=0.}

\item{batch}{factor. The known batch variable to be included in the adjustment model (variation to be removed).
Ignored, if adjust_batch=0.}

\item{run}{logical. If FALSE the normalization and evaluation are not run, but the function returns a data.frame
of parameters that will be run for inspection by the user.}

\item{evaluate}{logical. If FALSE the normalization methods will not be evaluated (faster).}

\item{eval_pcs}{numeric. The number of principal components to use for evaluation. Ignored if evaluation=FALSE.}

\item{eval_knn}{numeric. The number of nearest neighbors to use for evaluation. Ignored if evaluation=FALSE.}

\item{eval_weights}{matrix. A numeric data matrix to be used for weighted PCA in evaluation (genes in rows, cells in columns).}

\item{eval_kclust}{numeric. The number of clusters (> 1) to be used for pam tightness and stability evaluation.
If an array of integers, largest average silhoutte width (tightness) / maximum co-clustering compactness (stability) will be reported. If NULL, tightness and stability will be returned NA.}

\item{eval_negcon}{character. The genes to be used as negative controls for evaluation. These genes should
be expected not to change according to the biological phenomenon of interest. Ignored if evaluation=FALSE.
If NULL, correlations with negative controls will be returned NA.}

\item{eval_poscon}{character. The genes to be used as positive controls for evaluation. These genes should
be expected to change according to the biological phenomenon of interest. Ignored if evaluation=FALSE.
If NULL, correlations with positive controls will be returned NA.}

\item{params}{matrix or data.frame. If given, the algorithm will bypass creating the matrix of possible
parameters, and will use the given matrix. There are basically no checks as to whether this matrix is in the
right format, and is only intended to be used to feed the results of setting run=FALSE
back into the algorithm (see example).}

\item{verbose}{logical. If TRUE some messagges are printed.}

\item{conditional_pam}{logical. If TRUE then maximum ASW is separately computed for each biological condition (including NA), and a weighted average is returned.}
}
\value{
A list with the following elements:
\itemize{
\item{normalized_data}{ A list containing the normalized data matrix, log-scaled. NULL when evaluate = TRUE.}
\item{evaluation}{ A matrix containing raw evaluation metrics for each normalization method. Rows are sorted in the same order as in the ranks output matrix. NULL when evaluate = FALSE.}
\item{ranks}{ A matrix containing rank-scores for each normalization, including median rank across all scores. Rows are sorted by increasing median rank. NULL when evaluate = FALSE.}
\item{params}{ A data.frame with each row corresponding to a set of normalization parameters.}
}

If \code{run=FALSE} a \code{data.frame}
with each row corresponding to a set of normalization parameters.
}
\description{
This function is a high-level wrapper to apply and evaluate a variety of normalization
schemes to a specified expression matrix.
}
\details{
The function consists of four main steps: imputation, scaling normalization, adjusting for batch effects,
and evaluation of the normalization performance.

Note that if one wants to include the unnormalized data in the comparison, the identity function
must be included in the scaling list. Analogously, if one wants to avoid the imputation and/or include the
non-imputed data in the comparison, the identity function must be included.


If both \code{run=FALSE} the normalization and evaluation are not run, but the function returns a matrix of parameters that will be run for inspection by the user.


Evaluation metrics are defined in \code{\link[scone]{score_matrix}}. Each metric is assigned a signature for conversion to rank-score:
Positive-signature metrics increase with improving performance, including KNN_BIO,PAM_SIL, EXP_WV_COR, PAM_COMPACT.
Negative-signature metrics decrease with improving performance, including KNN_BATCH, EXP_QC_COR, EXP_RUV_COR, and EXP_UV_COR.
Rank-scores are computed so that higer-performing methods are assigned a lower-rank.
}

